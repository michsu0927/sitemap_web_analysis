README.md for sitemap-analysis-tool

# ğŸ—ºï¸ Sitemap Analysis Tool

A website structure and SEO analyzer that accepts input from **Web frontend** or **CLI**. Each analysis task is assigned a UUID, and results are stored in HTML, JSON, and TXT formats for sharing, reporting, or programmatic use.

---

## ğŸ“¦ Features

- Input via:
  - âœ… Frontend (paste URLs or upload sitemap.xml)
  - âœ… CLI (upload `.txt` file of URLs)
- Generates a unique UUID for each task
- Analyzes each page for:
  - HTTP status code
  - Title
  - Meta description
  - Content size
  - Depth from root
- Generates:
  - `report.html`
  - `report.json`
  - `urls.txt`
  - (for CLI) `input.txt`
- Maintains task index (`task_index.json`)
- Simple and extensible FastAPI + React architecture

---

## ğŸ“ Project Structure

sitemap-analysis-tool/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ analyzer.py
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â”œâ”€â”€ sitemap_parser.py
â”‚ â”‚ â”œâ”€â”€ report_writer.py
â”‚ â”‚ â””â”€â”€ task_index.py
â”‚ â”œâ”€â”€ templates/
â”‚ â”‚ â””â”€â”€ report_template.html
â”‚ â””â”€â”€ reports/
â”‚ â””â”€â”€ <uuid>/
â”‚ â”œâ”€â”€ report.html
â”‚ â”œâ”€â”€ report.json
â”‚ â”œâ”€â”€ urls.txt
â”‚ â””â”€â”€ input.txt (if CLI)
â”œâ”€â”€ frontend/ (optional)
â”‚ â””â”€â”€ ...
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

yaml
è¤‡è£½
ç·¨è¼¯

---

## ğŸš€ Getting Started (Backend Only)

```bash
# 1. Clone this repo
git clone https://github.com/yourname/sitemap-analysis-tool.git
cd sitemap-analysis-tool/backend

# 2. Set up virtual env (optional)
python3 -m venv venv
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start the server
uvicorn main:app --reload
```
ğŸ§  API Overview
â–¶ POST /analyze
Frontend input (URLs or sitemap)
```
Body: multipart/form-data

urls (optional): pasted URLs (newline separated)

file (optional): sitemap.xml file

Returns: { "uuid": "<uuid>", "report_url": "/report/<uuid>" }
```
â–¶ POST /cli/analyze
CLI upload of .txt URL file
```
Form field: file=@urls.txt

Returns: { "uuid": "<uuid>", "report_url": "/report/<uuid>" }
```
â–¶ GET /report/<uuid>
Returns rendered HTML report for a task.

â–¶ GET /report/<uuid>/report.json
Returns raw JSON of analysis result.

â–¶ GET /report/<uuid>/urls.txt
Returns all successfully analyzed URLs as plain text.

â–¶ GET /report/list
Returns task_index.json, including all UUIDs and timestamps.

ğŸ“„ Example CLI Upload
bash
è¤‡è£½
ç·¨è¼¯
curl -X POST http://localhost:8000/cli/analyze \
  -F 'file=@urls.txt'
ğŸ“‚ Example Output (per task)
graphql
reports/
â””â”€â”€ fc9b5aee/
    â”œâ”€â”€ report.html         # Final HTML report
    â”œâ”€â”€ report.json         # All result data (for API or front-end)
    â”œâ”€â”€ urls.txt            # Successfully analyzed URLs
    â””â”€â”€ input.txt           # Original URL input (if CLI)
ğŸ§ª Analysis Data Format (report.json)
json
{
  "uuid": "fc9b5aee",
  "analyzed_at": "2025-06-06T10:25:00",
  "total_urls": 23,
  "successful": 21,
  "failed": 2,
  "pages": [
    {
      "url": "https://example.com/",
      "status_code": 200,
      "title": "Home",
      "meta_description": "Welcome!",
      "depth": 0,
      "size": 10458
    }
  ]
}
ğŸ—ƒ Task Index (task_index.json)
[
  { "uuid": "fc9b5aee", "created_at": "2025-06-06T10:25:00" },
  { "uuid": "bdc82210", "created_at": "2025-06-06T11:09:13" }
]
ğŸ§° Developer Notes
All report files are written to backend/reports/<uuid>/

task_index.json is auto-updated for each new task

UUIDs are 8-char lowercase (uuid4().hex[:8])

âœ… TODO / Future Features
 Sitemap index parsing

 Progress API for live updates

 Graph visualization of page structure

 User login and private task tracking

ğŸ“ƒ License
MIT License Â© 2025 Mic Hsu & Contributors
